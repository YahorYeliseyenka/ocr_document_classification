{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "\n",
    "from os import path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lib.training_preparation import limit_by_type\n",
    "from lib.training_preparation import count_distinct_words\n",
    "from lib.training_preparation import get_tt_stratified_split\n",
    "\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_path = 'data/limit_5K_per_type_order_by_id_desc'\n",
    "\n",
    "df_files = ['cleaned.csv', \n",
    "            'stemmed.csv', \n",
    "            'lemmatized.csv']\n",
    "\n",
    "folds_num = 5\n",
    "min_ratio = 0.1\n",
    "limit = 1000\n",
    "\n",
    "if not path.exists(f'{dset_path}/10_tt_split'):\n",
    "    os.mkdir(f'{dset_path}/10_tt_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/limit_5K_per_type_order_by_id_desc/01_processed/cleaned.csv...\n",
      "Counting distinct words in documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31459/31459 [00:06<00:00, 4836.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting folds for training and testing process...\n",
      "Count of distinct words\n",
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:35<00:00,  7.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fasttext\n",
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:19<00:00,  3.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading data/limit_5K_per_type_order_by_id_desc/01_processed/stemmed.csv...\n",
      "Counting distinct words in documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31459/31459 [00:05<00:00, 5488.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting folds for training and testing process...\n",
      "Count of distinct words\n",
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:28<00:00,  5.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fasttext\n",
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:19<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading data/limit_5K_per_type_order_by_id_desc/01_processed/lemmatized.csv...\n",
      "Counting distinct words in documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31459/31459 [00:05<00:00, 5255.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting folds for training and testing process...\n",
      "Count of distinct words\n",
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:28<00:00,  5.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fasttext\n",
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:18<00:00,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for f in df_files:\n",
    "    in_path = f'{dset_path}/01_processed/{f}'\n",
    "    out_path = f'{dset_path}/10_tt_split/{f}'\n",
    "\n",
    "    print(f'Loading {in_path}...')\n",
    "    df = pd.read_csv(in_path, sep=';')\n",
    "    \n",
    "    df = limit_by_type(df, limit, 'id', 'type')\n",
    "\n",
    "    print('Counting distinct words in documents...')\n",
    "    df['codw'] = df['text'].progress_apply(count_distinct_words)\n",
    "\n",
    "    # print('Oversampling by type...')\n",
    "    # df = oversample_by_type(df)\n",
    "\n",
    "    print('Getting folds for training and testing process...')\n",
    "    df_kfolds = get_tt_stratified_split(df['type'], folds_num)\n",
    "\n",
    "    # print(f'Writing to {out_path}...')\n",
    "    # df.to_csv(out_path, index=False, sep=';')\n",
    "\n",
    "    print('Count of distinct words')\n",
    "    p = out_path.split('.')[0]\n",
    "    if not path.exists(p):\n",
    "        os.mkdir(p)\n",
    "    \n",
    "    dir_name = f'{p}/codw'\n",
    "    if not path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "\n",
    "    print('Saving...')\n",
    "    for fn in tqdm(range(folds_num)):\n",
    "        df_train = df[['codw', 'type']].iloc[df_kfolds[f'train_{fn}'].tolist()]\n",
    "        df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "        df_train.to_csv(f'{dir_name}/train_{fn}.csv', index=False, sep=';')\n",
    "        df_test = df[['codw', 'type']].iloc[df_kfolds[df_kfolds[f'test_{fn}'].notna()][f'test_{fn}'].astype(int).tolist()]\n",
    "        df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
    "        df_test.to_csv(f'{dir_name}/test_{fn}.csv', index=False, sep=';')\n",
    "\n",
    "    print('Fasttext')\n",
    "    if not path.exists(out_path[:-4]):\n",
    "        os.mkdir(out_path[:-4])\n",
    "    \n",
    "    dir_name = f'{out_path[:-4]}/fasttext'\n",
    "    if not path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "\n",
    "    df['id_typ_document_fasttext'] = '__class__' + df['type'].astype(str)\n",
    "    df['text_fasttext'] = df['id_typ_document_fasttext'] + ' ' + df['text']\n",
    "\n",
    "    print('Saving...')\n",
    "    for fn in tqdm(range(folds_num)):\n",
    "        df_train = df[['text_fasttext']].iloc[df_kfolds[f'train_{fn}'].tolist()]\n",
    "        df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "        df_train.to_csv(f'{dir_name}/train_{fn}.csv', header=None, index=False)\n",
    "        df_test = df[['text_fasttext']].iloc[df_kfolds[df_kfolds[f'test_{fn}'].notna()][f'test_{fn}'].astype(int).tolist()]\n",
    "        df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
    "        df_test.to_csv(f'{dir_name}/test_{fn}.csv', header=None, index=False)\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "135a5e2811e807938e4c3a7d694011e30bcf72392809a1353e1d4a87fa9f6710"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
